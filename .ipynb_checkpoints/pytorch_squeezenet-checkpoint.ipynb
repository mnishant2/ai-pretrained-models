{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import torchvision\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import copy\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
    "transforms = transforms.Compose([transforms.Resize((224,224)),\n",
    "                            transforms.ToTensor()])\n",
    "root = '/home/jeniffer/abs/blurDetection/'\n",
    "traindir = root+'/train/'\n",
    "testdir = root+'/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_output_classes = 2\n",
    "num_epochs = 10\n",
    "train_only_last_layer = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torchvision/models/squeezenet.py:94: UserWarning: nn.init.kaiming_uniform is now deprecated in favor of nn.init.kaiming_uniform_.\n",
      "  init.kaiming_uniform(m.weight.data)\n",
      "/usr/local/lib/python3.6/dist-packages/torchvision/models/squeezenet.py:92: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n",
      "  init.normal(m.weight.data, mean=0.0, std=0.01)\n"
     ]
    }
   ],
   "source": [
    "model_conv = torchvision.models.squeezenet1_1(pretrained=True)\n",
    "train_data = datasets.ImageFolder(traindir, transforms)\n",
    "test_data =  datasets.ImageFolder(testdir, transforms)\n",
    "dset_sizes = {} # empty dict\n",
    "dset_sizes['train'] = len(train_data)\n",
    "dset_sizes['val'] = len(test_data)\n",
    "dset_classes = train_data.classes \n",
    "print(dset_sizes['train'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "                        train_data,\n",
    "                        batch_size=15,\n",
    "                        shuffle=True,\n",
    "                        num_workers=4,\n",
    "                        pin_memory=True)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "                        test_data,\n",
    "                        batch_size=5,\n",
    "                        shuffle=False,\n",
    "                        num_workers=4,\n",
    "                        pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_gpu = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, filename):\n",
    "    print (\"=> Saving a new best\")\n",
    "    torch.save(state, filename)  # save checkpoint\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model = model\n",
    "    best_acc = 0.0\n",
    "    best_loss=1.0\n",
    "    # run for given number of epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                #optimizer = lr_scheduler(optimizer, epoch)\n",
    "                model.train(True)  # Set model to training mode\n",
    "            else:\n",
    "                model.train(False)  # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            total=0\n",
    "            correct=0\n",
    "            if phase == 'train':\n",
    "                phase_ = train_loader\n",
    "            else:\n",
    "                phase_ = val_loader\n",
    "\n",
    "            # Run through all data in mini batches\n",
    "            for data in phase_:\n",
    "                # get the inputs\n",
    "                inputs, labels = data\n",
    "\n",
    "                # wrap them in Variable\n",
    "                if use_gpu:\n",
    "                    inputs, labels = Variable(inputs.cuda()), \\\n",
    "                        Variable(labels.cuda())\n",
    "                else:\n",
    "                    inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward pass\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs.data, 1)\n",
    "\n",
    "                # calculating the loss\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # backward + optimize only if in training phase\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                # statistics for printing\n",
    "                #running_loss += loss.data[0]\n",
    "                running_loss += loss.item()\n",
    "                total += labels.size(0)\n",
    "                correct += (preds == labels).sum().item()\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / dset_sizes[phase]\n",
    "            epoch_acc = running_corrects / dset_sizes[phase]\n",
    "            new_acc=100*correct/total\n",
    "            print('{} Loss: {:.4f} {} Acc: {:.4f}'.format(phase,epoch_loss,phase,new_acc))\n",
    "\n",
    "            # save model if it performed better than\n",
    "            # any other previous model\n",
    "            if phase == 'val' and epoch_loss < best_loss:\n",
    "                best_acc = epoch_acc\n",
    "                best_loss=epoch_loss\n",
    "                best_model = copy.deepcopy(model)\n",
    "                filename='models/squeezenet_'+str(epoch)+'.pth.tar'\n",
    "                save_checkpoint({\n",
    "                'epoch': epoch,\n",
    "                'state_dict': model.state_dict(),\n",
    "                'best_accuracy': best_acc,\n",
    "                'best_loss':best_loss,\n",
    "                'optimizer_state_dict': optimizer.state_dict()\n",
    "                },filename)\n",
    "            elif phase=='val' and epoch_loss> best_loss:\n",
    "                print('model did not improve from {:.4f} val loss'.format(best_loss))\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "    return best_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_only_last_layer is True:\n",
    "    for param in model_conv.parameters():\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unknown format code 'f' for object of type 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-c025a4b974b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#optimizer_conv = optim.SGD(model_conv.classifier.parameters(), lr=0.001, momentum=0.9)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mmodel_conv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_conv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_conv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-3e5a0c6e7536>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, num_epochs)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0mnew_acc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mcorrect\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             print('{} Loss: {:.4f} {} Acc: {:.4f}'.format(phase,\n\u001b[0;32m---> 67\u001b[0;31m                 phase, epoch_loss,new_acc))\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# save model if it performed better than\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown format code 'f' for object of type 'str'"
     ]
    }
   ],
   "source": [
    "num_ftrs = 512\n",
    "model_conv.classifier._modules[\"1\"] = nn.Conv2d(num_ftrs, num_of_output_classes, kernel_size=(1, 1))\n",
    "model_conv.num_classes = num_of_output_classes\n",
    "\n",
    "\n",
    "if use_gpu:\n",
    "    model_conv = model_conv.cuda()\n",
    "#criterion = nn.BCELoss()\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "optimizer_conv=torch.optim.Adam(model_conv.classifier.parameters(), lr=0.0001)\n",
    "#optimizer_conv = optim.SGD(model_conv.classifier.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "model_conv = train_model(model_conv, criterion, optimizer_conv, num_epochs=num_epochs)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
